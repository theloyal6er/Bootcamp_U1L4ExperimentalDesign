{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The Sith Lords are concerned that their recruiting slogan, \"Give In to Your Anger,\" isn't very effective. Darth Vader develops an alternative slogan, \"Together We Can Rule the Galaxy.\" They compare the slogans on two groups of 50 captured droids each. In one group, Emperor Palpatine delivers the \"Anger\" slogan. In the other, Darth Vader presents the \"Together\" slogan. 20 droids convert to the Dark Side after hearing Palpatine's slogan, while only 5 droids convert after hearing Vader's. The Sith's data scientist concludes that \"Anger\" is a more effective slogan and should continue to be used.\n",
    "\n",
    "**A flaw I see here first is the demographic between Darth Vader and Emperor Palpatine. Although the slogans are different and you're wanting to test the effect of those quotes, there might be a bias in the delivery of these two quotes depending on the two people who delivered it. Do the droids react differently to Emperor Palpatine versus Dark Vader? Does one have more authority or influence than the other? Would the turnover in conversions change if they were the same speaker? Another interesting flaw I see is the nature of droids itself - is the droid programmed to respond quicker and better to anger (versus a quotation regarding togetherness) given the nature of droids? There may be an intrinsic bias within the droids to respond better to these types of anger-driven quotes so the effectiveness of that quote might be more \"natural\" than a particular slogan per say.**\n",
    "\n",
    "2) In the past, the Jedi have had difficulty with public relations. They send two envoys, Jar Jar Binks and Mace Windu, to four friendly and four unfriendly planets respectively, with the goal of promoting favorable feelings toward the Jedi. Upon their return, the envoys learn that Jar Jar was much more effective than Windu: Over 75% of the people surveyed said their attitudes had become more favorable after speaking with Jar Jar, while only 65% said their attitudes had become more favorable after speaking with Windu. This makes Windu angry, because he is sure that he had a better success rate than Jar Jar on every planet. The Jedi choose Jar Jar to be their representative in the future.\n",
    "\n",
    "**The biggest flaw seen here is most likely the audience to which both Jar Jar and Windu respectively both go to promote favorable feelings about the Jedi. By nature the planet which is more friendly than the other planet are going to have a favorable advantage to the envoy in promoting better public relations, a facet that relies on the friendliness of the recipient to be open-minded. The percentage only showed favoritism of 10% better from Jar Jar to Windu and given the circumstances of the unfriendly planets Windu had to deal with, there might be data alluding to Windu's effectiveness despite her circumstances. If they could see how those percentages would have changed if Windu went to friendly planets instead and compared attitudes afterwards, maybe there could be a better understanding of effectiveness thereafter.**\n",
    "\n",
    "3) A company with work sites in five different countries has sent you data on employee satisfaction rates for workers in Human Resources and workers in Information Technology. Most HR workers are concentrated in three of the countries, while IT workers are equally distributed across worksites. The company requests a report on satisfaction for each job type. You calculate average job satisfaction for HR and for IT and present the report.\n",
    "\n",
    "**The first bias that I see are the countries to which these jobs are distributed in. The IT job's satisfaction rates might have the least amount of bias because of how equally distributed they are between each of the five countries. The issue with HR employees being fixated in only three countries is that they have intrinsic bias based on the country they reside in. If one country naturally has a higher happiness score - i.e. benefits, company culture, weather, etc. - those biases may affect that office's happiness. There may be intrinsic bias within the satisfaction of the job itself - if IT jobs seem less satisfactory in general on a holistic level than HR, those scores will show in the data you collect. Statistically speaking as well, most HR employees tend to be female versus IT workers being male so whether satisfaction follows a certain gender type could be an interesting metric to understand as well.**\n",
    "\n",
    "4) When people install the Happy Days Fitness Tracker app, they are asked to \"opt in\" to a data collection scheme where their level of physical activity data is automatically sent to the company for product research purposes. During your interview with the company, they tell you that the app is very effective because after installing the app, the data show that people's activity levels rise steadily.\n",
    "\n",
    "**The big bias here is that when people install a fitness tracker app - and even furthermore opt in to send that data over to the company itself - there is a bias to a \"people's activity levels rising\" because they are initially motivated to work out more knowing their movements are being tracked. Because of the app itself there is a motivation for a person to work out more so their activity levels will rise steadily. It would be interesting to see if that app - given it will naturally cause a steady rise - is sustainable to the person to continue working out for a longer period of time. The app is effective by nature, not by anything the user or the app itself as done.**\n",
    "\n",
    "5) To prevent cheating, a teacher writes three versions of a test. She stacks the three versions together, first all copies of Version A, then all copies of Version B, then all copies of Version C. As students arrive for the exam, each student takes a test. When grading the test, the teacher finds that students who took Version B scored higher than students who took either Version A or Version C. She concludes from this that Version B is easier, and discards it.\n",
    "\n",
    "**I would be keen to understand the actual randomization of the tests itself - would stacking all the tests by A, then B, and then C be actually effective in achieving optimal randomization? There may be a possibility that the tests itself weren't randomized thus seeing a spike in scores within a certain test than the other two. Seeing where the students took each of the three test locationally in the classroom would show whether there was cheating involved or if the test itself was different in version. Stacking the tests possibly one by one individually - rather than all the stacks together test by test - would prevent suspicions of cheat if students are taking the test one by one.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
